{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9605d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vllm==0.10.2\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gen_answer.py\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import vllm\n",
    "\n",
    "def main():\n",
    "    # Model path\n",
    "    model_path = \"/mnt/nfs-mnj-hot-99/tmp/hokuyama/models/Qwen3-8B\"\n",
    "\n",
    "    # Initialize the LLM\n",
    "    llm = vllm.LLM(\n",
    "        model_path,\n",
    "        tensor_parallel_size=torch.cuda.device_count(),\n",
    "        gpu_memory_utilization=0.99,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=4096,\n",
    "        max_num_seqs=32,\n",
    "        disable_log_stats=True,\n",
    "        enable_prefix_caching=True,\n",
    "    )\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"You are an expert content moderator AI model. \n",
    "Your task is to analyze a Reddit comment against a specific community rule and predict the probability that the comment violates that rule.\n",
    "The probability must be a float value between 0.00 and 1.00, formatted to two decimal places.\n",
    "A probability closer to 1.00 indicates a high likelihood of a rule violation, and a probability closer to 0.00 indicates a low likelihood of a rule violation.\n",
    "\n",
    "YOUR OUTPUT MUST BE ONLY THE PROBABILITY VALUE, WITH NO OTHER TEXT, REASONING, OR EXPLANATION.\"\"\"\n",
    "\n",
    "    USER_PROMPT_TEMPLATE = \"\"\"### RULE AND CONTEXT\n",
    "- Rule: {rule_text}\n",
    "- Subreddit: {subreddit_name} (This is the community where the comment was posted.)\n",
    "\n",
    "### POSITIVE EXAMPLES (Comments that VIOLATE the Rule)\n",
    "- Example 1: {positive_example_1}\n",
    "- Example 2: {positive_example_2}\n",
    "\n",
    "### NEGATIVE EXAMPLES (Comments that DO NOT Violate the Rule)\n",
    "- Example 1: {negative_example_1}\n",
    "- Example 2: {negative_example_2}\n",
    "\n",
    "### COMMENT TO EVALUATE\n",
    "- Comment Body: {comment_body}\"\"\"\n",
    "\n",
    "    # Read data\n",
    "    df_train = pd.read_csv(\"jigsaw-agile-community-rules/train.csv\")\n",
    "\n",
    "    prompts = []\n",
    "    for i, r in df_train.iterrows():\n",
    "        user_prompt = USER_PROMPT_TEMPLATE.format(\n",
    "            rule_text=r['rule'],\n",
    "            subreddit_name=r['subreddit'],\n",
    "            positive_example_1=r['positive_example_1'],\n",
    "            positive_example_2=r['positive_example_2'],\n",
    "            negative_example_1=r['negative_example_1'],\n",
    "            negative_example_2=r['negative_example_2'],\n",
    "            comment_body=r['body']\n",
    "        )\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': user_prompt}\n",
    "        ]\n",
    "        prompts.append(messages)\n",
    "\n",
    "    outputs = llm.chat(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            seed=0,\n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=4,\n",
    "            temperature=0,\n",
    "            repetition_penalty=1.05,\n",
    "        ),\n",
    "        chat_template_kwargs={\"enable_thinking\": False},\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    responses =  [output.outputs[0].text for output in outputs]\n",
    "\n",
    "    answers = []\n",
    "    for response in responses:\n",
    "        try:\n",
    "            answer = float(response)\n",
    "            answers.append(answer)\n",
    "        except:\n",
    "            answers.append(0.5)\n",
    "\n",
    "    df_train[\"llm_output\"] = answers\n",
    "\n",
    "    # Save as Parquet file\n",
    "    df_train.to_parquet('output.parquet', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gen_answer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f58dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"output.parquet\")\n",
    "df[\"rule_violation\"] = df[\"llm_output\"]\n",
    "df[[\"row_id\", \"rule_violation\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa192b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "df = pd.read_parquet(\"output.parquet\")\n",
    "roc_auc_score(df[\"rule_violation\"], df[\"llm_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29038b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
